{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "Módulo2-Notas\nCurso: Data Analysis with Python (IBM)\nMateria: Ciencia y analítica de datos\nMaximiliano Morones Gómez\nMatrícula: A01793815",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"What is the purpose of data wrangling?\"\nData wrangling is the process of converting data from the initial format to a format that may be better for analysis.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"Identify missing values\"\nConvert \"?\" to NaN\nimport numpy as np\n\n# replace \"?\" to NaN\ndf.replace(\"?\", np.nan, inplace = True)\ndf.head(5)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"Evaluating for Missing Data\"\nThe missing values are converted by default. We use the following functions to identify these missing values. \nThere are two methods to detect missing data:\n.isnull()\n.notnull()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"Count missing values in each column\"\nUsing a for loop in Python, we can quickly figure out the number of missing values in each column.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"Deal with missing data\"\nHow to deal with missing data?\nDrop data\na. Drop the whole row\nb. Drop the whole column\nReplace data\na. Replace it by mean\nb. Replace it by frequency\nc. Replace it based on other functions\nWhole columns should be dropped only if most entries in the column are empty.\nWe have some freedom in choosing which method to replace data; however, some methods may seem more reasonable than others.\nWe will apply each method to many different columns:\n\nReplace by mean:\n\"normalized-losses\": 41 missing data, replace them with mean\n\"stroke\": 4 missing data, replace them with mean\n\"bore\": 4 missing data, replace them with mean\n\"horsepower\": 2 missing data, replace them with mean\n\"peak-rpm\": 2 missing data, replace them with mean\n\nReplace by frequency:\n\"num-of-doors\": 2 missing data, replace them with \"four\".\nReason: 84% sedans is four doors. Since four doors is most frequent, it is most likely to occur\n\nDrop the whole row:\n\"price\": 4 missing data, simply delete the whole row\nReason: price is what we want to predict. Any data entry without price data cannot be used for prediction; therefore \nany row now without price data is not useful to us\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"Calculate the mean value for the \"normalized-losses\" column\"\navg_norm_loss = df[\"normalized-losses\"].astype(\"float\").mean(axis=0)\nprint(\"Average of normalized-losses:\", avg_norm_loss)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"Replace \"NaN\" with mean value in \"normalized-losses\" column\"\ndf[\"normalized-losses\"].replace(np.nan, avg_norm_loss, inplace=True)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"Calculate the mean value for the \"bore\" column\"\navg_bore=df['bore'].astype('float').mean(axis=0)\nprint(\"Average of bore:\", avg_bore)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"Replace \"NaN\" with the mean value in the \"bore\" column\"\ndf[\"bore\"].replace(np.nan, avg_bore, inplace=True)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"Data Standardization\"\nStandardization is the process of transforming data into a common format, allowing the researcher to make\nthe meaningful comparison.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"Data Normalization\"\nNormalization is the process of transforming values of several variables into a similar range. Typical \nnormalizations include scaling the variable so the variable average is 0, scaling the variable so the variance is 1, or \nscaling the variable so the variable values range from 0 to 1.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"Binning\"\nBinning is a process of transforming continuous numerical variables into discrete categorical 'bins' for grouped analysis.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}