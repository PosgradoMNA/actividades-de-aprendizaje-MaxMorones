{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "Módulo1-Notas\nCurso: Data Analysis with Python (IBM)\nMateria: Ciencia y analítica de datos\nMaximiliano Morones Gómez\nMatrícula: A01793815",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"Data Acquisition\"\nThere are various formats for a dataset: .csv, .json, .xlsx etc. The dataset can be stored in different places, in \na local machine or sometimes online.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Learn how to load a dataset into our Jupyter Notebook.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "For these case the Dataset is an online source and it is in a CSV format.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Data source: https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\nData type: csv",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "The Pandas Library is a useful tool that enables us to read various datasets into a dataframe.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Jupyter notebook platforms have a built-in Pandas Library so that all we need to do is import Pandas\nwithout installing.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "You are running the lab in your browser, so we will install the libraries using piplite\nimport piplite\nimport micropip\nawait piplite.install(['pandas'])\nawait piplite.install(['matplotlib'])\nawait piplite.install(['scipy'])\nawait piplite.install(['seaborn'])\nawait micropip.install(['ipywidgets'],keep_going=True)\nawait micropip.install(['tqdm'],keep_going=True)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# import pandas library\nimport pandas as pd\nimport numpy as np",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "This function will download the dataset into your browser\nfrom pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"Read Data\"\nWe use pandas.read_csv() function to read the csv file. In the brackets, we put the file path along\nwith a quotation mark so that pandas will read the file into a dataframe from that address. The file \npath can be either an URL or your local file address.\n\nThe data does not include headers, we can add an argument headers = None inside the read_csv() method so \nthat pandas will not automatically set the first row as a header.\n\nYou can also assign the dataset to any variable you create.\npath = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/auto.csv\"\n\nYou will need to download the dataset; if you are running locally.\nawait download(path, \"auto.csv\")\npath=\"auto.csv\"\n\nThis dataset was hosted on IBM Cloud object.\n# Import pandas library\nimport pandas as pd\n\n# Read the online file by the URL provides above, and assign it to variable \"df\"\ndf = pd.read_csv(path, header=None)\n\nAfter reading the dataset, we can use the dataframe.head(n) method to check the top n rows of the dataframe, where n \nis an integer. Contrary to dataframe.head(n), dataframe.tail(n) will show you the bottom n rows of the dataframe.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"Save Dataset\"\nPandas enables us to save the dataset to csv. By using the dataframe.to_csv() method, you \ncan add the file path and name along with quotation marks in the brackets.\n\nFor example, if you would save the dataframe df as automobile.csv to your local machine, you may use the syntax below, where index = False means \nthe row names will not be written.\n\ndf.to_csv(\"automobile.csv\", index=False)\n\nWe can also read and save other file formats. We can use similar functions like pd.read_csv() \nand df.to_csv() for other data formats.\n\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\"Basic Insight of Dataset\"\nData Types\nData has a variety of types.\nThe main types stored in Pandas dataframes are object, float, int, bool and datetime64. \n\nIn order to better learn about each attribute, it is always good for us to know the data type of each column.\n\nIn Pandas:\ndf.dtypes\nA series with the data type of each column is returned.\n\nDescribe\nIf we would like to get a statistical summary of each column e.g. count, column mean value, column \nstandard deviation, etc., we use the describe method:\ndataframe.describe() # This method will provide various summary statistics, excluding NaN (Not a Number) values.\ndf.describe() # This shows the statistical summary of all numeric-typed (int, float) columns.\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}